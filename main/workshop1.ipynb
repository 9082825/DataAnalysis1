{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef02214b",
   "metadata": {},
   "source": [
    "### Data Analysis Mathematics, Algorithms and Modeling\n",
    "`PROG8431 - Fall 2025 - Section 1`\n",
    "\n",
    "Problem Analysis Workshop 1 - Data Collection and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3966b0",
   "metadata": {},
   "source": [
    "\n",
    "#### THE TEAM\n",
    "1. George Jose\n",
    "2. Lawal Oluwafemi\n",
    "3. Kamamo Lesley \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61516bf3",
   "metadata": {},
   "source": [
    "#### `FIELD OF INQUIRY`\n",
    "CyberSecurity\n",
    "\n",
    "#### `The Problem`\n",
    "**How does poorly defined cybersecurity protocols affect telecom networks**\n",
    "\n",
    "#### `The Prompt to Gen Ai`\n",
    "You are a Cybersecurity analyst. Analyze the impact of poorly defined research questions in cybersecurity. Provide examples where vague or overly broad security goals led to ineffective strategies or wasted resources. Compare these with cases where well-defined, specific questions produced actionable results. Summarize key recommendations for framing precise and effective research questions in cybersecurity.\n",
    "\n",
    "#### `ESSAY ON FINDINGS`\n",
    "\n",
    "Below is the short 100 word essay, from Gen AI to base our findings on the Field of Cyber Security:\n",
    "\n",
    "Poorly defined research questions in cybersecurity often lead to wasted resources and weak defenses. Broad goals like “prevent cyberattacks” lack focus, causing organizations to invest in generic tools rather than addressing real threats. For example, vague cloud security strategies often overlook identity management, a frequent breach cause. In contrast, well-defined questions such as “How to cut phishing success rates by 50% in one year?” enable measurable, actionable solutions like user training and email filtering. Effective cybersecurity research demands precision, scope, and context. Clear questions drive targeted defenses, maximize resources, and strengthen resilience against evolving threats\n",
    "\n",
    "\n",
    "#### `Goal of this project:` \n",
    "\n",
    "The goal is to detect potential intrusions (cyberattacks) in network sessions using features like packet size, login attempts, session duration, IP reputation, and unusual access patterns. \n",
    "\n",
    "#### `Sources of the Information`\n",
    "https://www.kaggle.com/datasets/dnkumars/cybersecurity-intrusion-detection-dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9f3a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.1' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"e:/CONESTOGA/AI and ML/DataAnalysisMath/wk01/.venv/Scripts/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb45ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "file_path = \"./data/cybersecurity_intrusion_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# display the first 5 rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispaly the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e684e",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcc91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display shape - entire dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f73fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905be797",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "- This process is to standardize data such that the dataset is transformed for better analysis\n",
    "- Some of the quiestion we could ask oursleves:\n",
    "1. How to deal with missing values (empty cells)\n",
    "2. Should we normalize data types (Convert numbers stored as text to numbers)\n",
    "3. How to deal with duplicated values\n",
    "4. Fixing Structural inconsistencies (Change text to upper/lower case, replacing some text - gender, dropping of unnecessary columns)\n",
    "5. Check for Outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35346e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
